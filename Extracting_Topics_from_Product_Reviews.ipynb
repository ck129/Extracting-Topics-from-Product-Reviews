{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extracting Topics from Product Reviews.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HSwMEgYq-WD",
        "colab_type": "text"
      },
      "source": [
        "**LDA for Topic Modeling in Python**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTTViCpOrKA_",
        "colab_type": "text"
      },
      "source": [
        "The data set contains user reviews for different products in the food category. We will use LDA to group the user reviews into 5 categories.The first step, as always, is to import the data set along with the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5UdVfifq_qW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f2b7010-d82a-46f7-afca-482014f1a1ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnYt1wR4q_sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "reviews_datasets = pd.read_csv('drive/My Drive/data/tm/Reviews.csv')\n",
        "reviews_datasets = reviews_datasets.head(20000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFf3lWo8q_wX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "4797a2b1-5563-4b6f-d8d2-84a2cdeb32a7"
      },
      "source": [
        "#dropna is used to remove missing values.\n",
        "reviews_datasets.dropna()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>19996</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A1XRXZI5KOMVDD</td>\n",
              "      <td>KAF1958 \"amandaf0626\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1307664000</td>\n",
              "      <td>Crispy and tart</td>\n",
              "      <td>Deep River Salt &amp; Vinegar chips are thick and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>19997</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A7G9M0IE7LABX</td>\n",
              "      <td>Kevin</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1307059200</td>\n",
              "      <td>Exceeded my expectations. One of the best chip...</td>\n",
              "      <td>I was very skeptical about buying a brand of c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>19998</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A38J5PRUDESMZF</td>\n",
              "      <td>ray</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1305763200</td>\n",
              "      <td>Awesome Goodness! (deep river kettle chips, sw...</td>\n",
              "      <td>Before you turn to other name brands out there...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>19999</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A17TPOSAG43GSM</td>\n",
              "      <td>Herrick</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1303171200</td>\n",
              "      <td>Pretty good, but prefer other jalapeno chips</td>\n",
              "      <td>I was expecting some \"serious flavor\" as it wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>20000</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A3LWC833HQIG7J</td>\n",
              "      <td>austin_Larry</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1295568000</td>\n",
              "      <td>Excellent chips, full of flavor and just the r...</td>\n",
              "      <td>I purchased the Salt and Vinegar chips and hav...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Id  ...                                               Text\n",
              "0          1  ...  I have bought several of the Vitality canned d...\n",
              "1          2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2          3  ...  This is a confection that has been around a fe...\n",
              "3          4  ...  If you are looking for the secret ingredient i...\n",
              "4          5  ...  Great taffy at a great price.  There was a wid...\n",
              "...      ...  ...                                                ...\n",
              "19995  19996  ...  Deep River Salt & Vinegar chips are thick and ...\n",
              "19996  19997  ...  I was very skeptical about buying a brand of c...\n",
              "19997  19998  ...  Before you turn to other name brands out there...\n",
              "19998  19999  ...  I was expecting some \"serious flavor\" as it wa...\n",
              "19999  20000  ...  I purchased the Salt and Vinegar chips and hav...\n",
              "\n",
              "[20000 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJDn_MxG8aQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "7b81d316-f689-45a0-e00b-a6057844d2e3"
      },
      "source": [
        "reviews_datasets['Text'].describe"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of 0        I have bought several of the Vitality canned d...\n",
              "1        Product arrived labeled as Jumbo Salted Peanut...\n",
              "2        This is a confection that has been around a fe...\n",
              "3        If you are looking for the secret ingredient i...\n",
              "4        Great taffy at a great price.  There was a wid...\n",
              "                               ...                        \n",
              "19995    Deep River Salt & Vinegar chips are thick and ...\n",
              "19996    I was very skeptical about buying a brand of c...\n",
              "19997    Before you turn to other name brands out there...\n",
              "19998    I was expecting some \"serious flavor\" as it wa...\n",
              "19999    I purchased the Salt and Vinegar chips and hav...\n",
              "Name: Text, Length: 20000, dtype: object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls17VkZXr6np",
        "colab_type": "text"
      },
      "source": [
        "Before we can apply LDA, we need to create vocabulary of all the words in our data.\n",
        "We could do so with the help of a count vectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PK5sOfXq_3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "doc_term_matrix = count_vect.fit_transform(reviews_datasets['Text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiO8ueHFsKtx",
        "colab_type": "text"
      },
      "source": [
        "Now let's look at our document term matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqpqA04Zq_5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2042c6d4-c4d0-4e7f-a05f-4429112f726c"
      },
      "source": [
        "doc_term_matrix"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<20000x26618 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1064912 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg2_6TZB9nCE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "66c096ab-18d0-40d1-f062-bfba4cc35e83"
      },
      "source": [
        "df = pd.DataFrame(doc_term_matrix.toarray(), columns=count_vect.get_feature_names())\n",
        "print(df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       00  000  0003  000kwh  002  ...  zupas  zuppa  zwieback  çaykur  ît\n",
            "0       0    0     0       0    0  ...      0      0         0       0   0\n",
            "1       0    0     0       0    0  ...      0      0         0       0   0\n",
            "2       0    0     0       0    0  ...      0      0         0       0   0\n",
            "3       0    0     0       0    0  ...      0      0         0       0   0\n",
            "4       0    0     0       0    0  ...      0      0         0       0   0\n",
            "...    ..  ...   ...     ...  ...  ...    ...    ...       ...     ...  ..\n",
            "19995   0    0     0       0    0  ...      0      0         0       0   0\n",
            "19996   0    0     0       0    0  ...      0      0         0       0   0\n",
            "19997   0    0     0       0    0  ...      0      0         0       0   0\n",
            "19998   0    0     0       0    0  ...      0      0         0       0   0\n",
            "19999   0    0     0       0    0  ...      0      0         0       0   0\n",
            "\n",
            "[20000 rows x 26618 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh8PygzXsOLJ",
        "colab_type": "text"
      },
      "source": [
        "Next, we will use LDA to create topics along with the probability distribution for each word in our vocabulary for each topic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJwjRrPdq_8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "22b057d3-3434-454c-e19d-2dc26e60917a"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
        "LDA.fit(doc_term_matrix)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
              "                          evaluate_every=-1, learning_decay=0.7,\n",
              "                          learning_method='batch', learning_offset=10.0,\n",
              "                          max_doc_update_iter=100, max_iter=10,\n",
              "                          mean_change_tol=0.001, n_components=5, n_jobs=None,\n",
              "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
              "                          total_samples=1000000.0, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKXzfstxsdvM",
        "colab_type": "text"
      },
      "source": [
        " randomly fetches 10 words from our vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqWtQPXxrABb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "bf5bfd18-d86f-491d-85be-261d799875bd"
      },
      "source": [
        "\n",
        "\n",
        "import random\n",
        "for i in range(10):\n",
        "  random_id = random.randint(0,len(count_vect.get_feature_names()))\n",
        "  print(count_vect.get_feature_names()[random_id])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "refreshed\n",
            "thrives\n",
            "pinacolada\n",
            "interpreter\n",
            "picture\n",
            "cee\n",
            "phobias\n",
            "surveys\n",
            "proof\n",
            "excellentprice\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBAEYr0OswrO",
        "colab_type": "text"
      },
      "source": [
        "Let's find 10 words with the highest probability for the first topic. To get the first\n",
        "topic, we use the components_ attribute and pass a 0 index as the value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_DXXQ7MrAEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_topic = LDA.components_[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_SKZeIns-w6",
        "colab_type": "text"
      },
      "source": [
        "Once sorted, the 10 words with the highest probabilities will now belong to the last\n",
        "10 indexes of the array. The following script returns the indexes of the 10 words with\n",
        "the highest probabilities:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XvHcmshrAHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_topic_words = first_topic.argsort()[-10:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbzUDT0GtDUF",
        "colab_type": "text"
      },
      "source": [
        "These indexes can then be used to retrieve the value of the words from\n",
        "the count_vect object, which can be done like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEFQhtKhrAJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "0eb1406f-c715-435c-d54d-9848afc2de29"
      },
      "source": [
        "for i in top_topic_words:\n",
        "  print(count_vect.get_feature_names()[i])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that\n",
            "you\n",
            "are\n",
            "is\n",
            "to\n",
            "of\n",
            "it\n",
            "br\n",
            "and\n",
            "the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZo8Xf1MtJNy",
        "colab_type": "text"
      },
      "source": [
        "Let's print the 10 words with highest probabilities for all the five topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjKjk1ZzrAMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "e04717b8-817f-4399-d288-cc4b30551559"
      },
      "source": [
        "for i,topic in enumerate(LDA.components_):\n",
        "  print(f'Top 10 words for topic #{i}:')\n",
        "  print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
        "  print('\\n')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 words for topic #0:\n",
            "['that', 'you', 'are', 'is', 'to', 'of', 'it', 'br', 'and', 'the']\n",
            "\n",
            "\n",
            "Top 10 words for topic #1:\n",
            "['they', 'br', 'is', 'for', 'of', 'my', 'it', 'to', 'and', 'the']\n",
            "\n",
            "\n",
            "Top 10 words for topic #2:\n",
            "['was', 'for', 'is', 'of', 'in', 'this', 'to', 'it', 'and', 'the']\n",
            "\n",
            "\n",
            "Top 10 words for topic #3:\n",
            "['br', 'tea', 'to', 'of', 'this', 'is', 'coffee', 'and', 'it', 'the']\n",
            "\n",
            "\n",
            "Top 10 words for topic #4:\n",
            "['ounce', 'pack', 'pasta', 'product', 'amazon', 'href', 'gp', 'http', 'www', 'com']\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsz_7SkztTud",
        "colab_type": "text"
      },
      "source": [
        "As a final step, we will add a column to the original data frame that will store the\n",
        "topic for the text. To do so, we can use LDA.transform() method and pass it our\n",
        "document-term matrix. This method will assign the probability of all the topics to\n",
        "each document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMwuwwX2rAPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c223d0b-8be7-42b8-cdae-bd342259d285"
      },
      "source": [
        "\n",
        "topic_values = LDA.transform(doc_term_matrix)\n",
        "topic_values.shape\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31qEFHSatYre",
        "colab_type": "text"
      },
      "source": [
        "To find the topic index with maximum value, we can call the argmax() method and\n",
        "pass 1 as the value for the axis parameter.\n",
        "we add a new column for topic in the data frame and assigns the\n",
        "topic value to each row in the column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEccG5nXrAR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "reviews_datasets['Topic'] = topic_values.argmax(axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nq3li5Jtfer",
        "colab_type": "text"
      },
      "source": [
        "Let's now see how the data set looks:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRiNobDvrAVq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "47cdcc7a-5cad-4949-f049-5355e61aadeb"
      },
      "source": [
        "reviews_datasets.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id   ProductId  ...                                               Text Topic\n",
              "0   1  B001E4KFG0  ...  I have bought several of the Vitality canned d...     1\n",
              "1   2  B00813GRG4  ...  Product arrived labeled as Jumbo Salted Peanut...     2\n",
              "2   3  B000LQOCH0  ...  This is a confection that has been around a fe...     3\n",
              "3   4  B000UA0QIQ  ...  If you are looking for the secret ingredient i...     0\n",
              "4   5  B006K2ZZ7K  ...  Great taffy at a great price.  There was a wid...     2\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwZQNMyjup_r",
        "colab_type": "text"
      },
      "source": [
        "**NMF for Topic Modeling in Python**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6PwviM4q_1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "9fe3b395-457a-47e2-b20e-81faad21752e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "reviews_datasets = pd.read_csv('drive/My Drive/data/tm/Reviews.csv')\n",
        "reviews_datasets = reviews_datasets.head(20000)\n",
        "reviews_datasets.dropna()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>19996</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A1XRXZI5KOMVDD</td>\n",
              "      <td>KAF1958 \"amandaf0626\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1307664000</td>\n",
              "      <td>Crispy and tart</td>\n",
              "      <td>Deep River Salt &amp; Vinegar chips are thick and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>19997</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A7G9M0IE7LABX</td>\n",
              "      <td>Kevin</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1307059200</td>\n",
              "      <td>Exceeded my expectations. One of the best chip...</td>\n",
              "      <td>I was very skeptical about buying a brand of c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>19998</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A38J5PRUDESMZF</td>\n",
              "      <td>ray</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1305763200</td>\n",
              "      <td>Awesome Goodness! (deep river kettle chips, sw...</td>\n",
              "      <td>Before you turn to other name brands out there...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>19999</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A17TPOSAG43GSM</td>\n",
              "      <td>Herrick</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1303171200</td>\n",
              "      <td>Pretty good, but prefer other jalapeno chips</td>\n",
              "      <td>I was expecting some \"serious flavor\" as it wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>20000</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A3LWC833HQIG7J</td>\n",
              "      <td>austin_Larry</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1295568000</td>\n",
              "      <td>Excellent chips, full of flavor and just the r...</td>\n",
              "      <td>I purchased the Salt and Vinegar chips and hav...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Id  ...                                               Text\n",
              "0          1  ...  I have bought several of the Vitality canned d...\n",
              "1          2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2          3  ...  This is a confection that has been around a fe...\n",
              "3          4  ...  If you are looking for the secret ingredient i...\n",
              "4          5  ...  Great taffy at a great price.  There was a wid...\n",
              "...      ...  ...                                                ...\n",
              "19995  19996  ...  Deep River Salt & Vinegar chips are thick and ...\n",
              "19996  19997  ...  I was very skeptical about buying a brand of c...\n",
              "19997  19998  ...  Before you turn to other name brands out there...\n",
              "19998  19999  ...  I was expecting some \"serious flavor\" as it wa...\n",
              "19999  20000  ...  I purchased the Salt and Vinegar chips and hav...\n",
              "\n",
              "[20000 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll6khrKXu2EU",
        "colab_type": "text"
      },
      "source": [
        "In the previous section we used count vectorizer, but in this section we will use\n",
        "TFIDF vectorizer since NMF works with TFIDF. We will create a document term\n",
        "matrix with TFIDF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f66YkETgu7fX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "doc_term_matrix = tfidf_vect.fit_transform(reviews_datasets['Text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWrOXOPQu6r_",
        "colab_type": "text"
      },
      "source": [
        "Once the document term matrix is generated, we can create a probability matrix that\n",
        "contains probabilities of all the words in the vocabulary for all the topics. To do so,\n",
        "we can use the NMF class from the sklearn.decomposition module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOwwba4rvCSI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4ca2ccd4-0241-4bee-b165-1f8c763bce01"
      },
      "source": [
        "from sklearn.decomposition import NMF\n",
        "nmf = NMF(n_components=5, random_state=42)\n",
        "nmf.fit(doc_term_matrix )"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
              "    n_components=5, random_state=42, shuffle=False, solver='cd', tol=0.0001,\n",
              "    verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H28EhUF0u2JM",
        "colab_type": "text"
      },
      "source": [
        "randomly get 10 words from our vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBMxMkUzvKiW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "1bb06db1-3bda-4d97-b68e-ee35238bc44a"
      },
      "source": [
        "import random\n",
        "for i in range(10):\n",
        "  random_id = random.randint(0,len(tfidf_vect.get_feature_names()))\n",
        "  print(tfidf_vect.get_feature_names()[random_id])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mid\n",
            "foldiers\n",
            "mir\n",
            "hartshorn\n",
            "platoon\n",
            "parts\n",
            "junkyards\n",
            "cannister\n",
            "garfield\n",
            "hesitantly\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUpCY0oQu2NT",
        "colab_type": "text"
      },
      "source": [
        "Next, we will retrieve the probability vector of words for the first topic and will\n",
        "retrieve the indexes of the ten words with the highest probabilities:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baXHKCIXvTpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_topic = nmf.components_[0]\n",
        "top_topic_words = first_topic.argsort()[-10:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msl0Aj8CvTEc",
        "colab_type": "text"
      },
      "source": [
        "These indexes can now be passed to the tfidf_vect object to retrieve the actual words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwSD6sHAvcqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "3198cc38-a0b5-4548-f1b4-09eac040e6d0"
      },
      "source": [
        "for i in top_topic_words:\n",
        "  print(tfidf_vect.get_feature_names()[i])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in\n",
            "tea\n",
            "was\n",
            "of\n",
            "to\n",
            "and\n",
            "this\n",
            "is\n",
            "the\n",
            "it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KREAnxQPu2G6",
        "colab_type": "text"
      },
      "source": [
        "Lets's now print the ten words with highest probabilities for each of the topics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziBmrGTVv2oY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "325878a6-646b-48b9-c05b-6168597ca916"
      },
      "source": [
        "for i,topic in enumerate(nmf.components_):\n",
        "  print(f'Top 10 words for topic #{i}:')\n",
        "  print([tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
        "  print('\\n')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 words for topic #0:\n",
            "['in', 'tea', 'was', 'of', 'to', 'and', 'this', 'is', 'the', 'it']\n",
            "\n",
            "\n",
            "Top 10 words for topic #1:\n",
            "['you', 'of', 'chips', 'to', 'and', 'the', 'them', 'these', 'are', 'they']\n",
            "\n",
            "\n",
            "Top 10 words for topic #2:\n",
            "['with', 'juice', 'in', 'or', 'that', 'to', 'you', 'of', 'the', 'br']\n",
            "\n",
            "\n",
            "Top 10 words for topic #3:\n",
            "['and', 'bold', 'strong', 'cups', 'of', 'is', 'this', 'the', 'cup', 'coffee']\n",
            "\n",
            "\n",
            "Top 10 words for topic #4:\n",
            "['and', 'to', 'treats', 'we', 'my', 'her', 'he', 'food', 'she', 'dog']\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su6cH3JrvtPO",
        "colab_type": "text"
      },
      "source": [
        "we add the topics to the data set and displays the first five rows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbkSdPzpvyw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "ce7a55dd-c618-4941-af2d-0a93db3ad9e3"
      },
      "source": [
        "\n",
        "topic_values = nmf.transform(doc_term_matrix)\n",
        "reviews_datasets['Topic'] = topic_values.argmax(axis=1)\n",
        "reviews_datasets.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id   ProductId  ...                                               Text Topic\n",
              "0   1  B001E4KFG0  ...  I have bought several of the Vitality canned d...     4\n",
              "1   2  B00813GRG4  ...  Product arrived labeled as Jumbo Salted Peanut...     0\n",
              "2   3  B000LQOCH0  ...  This is a confection that has been around a fe...     0\n",
              "3   4  B000UA0QIQ  ...  If you are looking for the secret ingredient i...     0\n",
              "4   5  B006K2ZZ7K  ...  Great taffy at a great price.  There was a wid...     0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DCK_A7Zv4NZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}